{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71a329f0",
   "metadata": {},
   "source": [
    "# vLLM Qwen1.5-72B-Chat-AWQ vLLM deployment guide\n",
    "In this tutorial, you will use LMI container from DLC to SageMaker and run inference with it.\n",
    "\n",
    "Please make sure the following permission granted before running the notebook:\n",
    "\n",
    "- S3 bucket push access\n",
    "- SageMaker access\n",
    "\n",
    "## Step 1: Let's bump up SageMaker and import stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67fa3208",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting boto3==1.34.101\n",
      "  Downloading boto3-1.34.101-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting botocore<1.35.0,>=1.34.101 (from boto3==1.34.101)\n",
      "  Downloading botocore-1.34.111-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from boto3==1.34.101) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from boto3==1.34.101) (0.10.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.10/site-packages (from botocore<1.35.0,>=1.34.101->boto3==1.34.101) (2.9.0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /opt/conda/lib/python3.10/site-packages (from botocore<1.35.0,>=1.34.101->boto3==1.34.101) (1.26.18)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.101->boto3==1.34.101) (1.16.0)\n",
      "Downloading boto3-1.34.101-py3-none-any.whl (139 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading botocore-1.34.111-py3-none-any.whl (12.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m74.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: botocore, boto3\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.34.51\n",
      "    Uninstalling botocore-1.34.51:\n",
      "      Successfully uninstalled botocore-1.34.51\n",
      "  Attempting uninstall: boto3\n",
      "    Found existing installation: boto3 1.34.51\n",
      "    Uninstalling boto3-1.34.51:\n",
      "      Successfully uninstalled boto3-1.34.51\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "aiobotocore 2.12.1 requires botocore<1.34.52,>=1.34.41, but you have botocore 1.34.111 which is incompatible.\n",
      "amazon-sagemaker-jupyter-scheduler 3.0.7 requires jupyter-scheduler==2.5, but you have jupyter-scheduler 2.5.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed boto3-1.34.101 botocore-1.34.111\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install sagemaker --upgrade  --quiet\n",
    "%pip install boto3==1.34.101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec9ac353",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import Model, image_uris, serializers, deserializers\n",
    "\n",
    "role = sagemaker.get_execution_role()  # execution role for the endpoint\n",
    "sess = sagemaker.session.Session()  # sagemaker session for interacting with different AWS APIs\n",
    "region = sess._region_name  # region name of the current SageMaker Studio environment\n",
    "account_id = sess.account_id()  # account_id of the current SageMaker Studio environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81deac79",
   "metadata": {},
   "source": [
    "## Step 2: Start preparing model artifacts\n",
    "In LMI contianer, we expect some artifacts to help setting up the model\n",
    "- serving.properties (required): Defines the model server settings\n",
    "- model.py (optional): A python file to define the core inference logic\n",
    "- requirements.txt (optional): Any additional pip wheel need to install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b011bf5f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing serving.properties\n"
     ]
    }
   ],
   "source": [
    "%%writefile serving.properties\n",
    "engine=Python\n",
    "option.model_id=Qwen/Qwen1.5-72B-Chat-AWQ\n",
    "option.task=text-generation\n",
    "option.trust_remote_code=true\n",
    "option.tensor_parallel_degree=4\n",
    "option.rolling_batch=vllm\n",
    "option.quantize=awq\n",
    "option.dtype=fp16\n",
    "option.max_rolling_batch_size=64\n",
    "option.max_model_len=10272"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0142973",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mymodel/\n",
      "mymodel/serving.properties\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "mkdir mymodel\n",
    "mv serving.properties mymodel/\n",
    "tar czvf mymodel.tar.gz mymodel/\n",
    "rm -rf mymodel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e58cf33",
   "metadata": {},
   "source": [
    "## Step 3: Start building SageMaker endpoint\n",
    "In this step, we will build SageMaker endpoint from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d955679",
   "metadata": {},
   "source": [
    "### Getting the container image URI\n",
    "\n",
    "[Large Model Inference available DLC](https://github.com/aws/deep-learning-containers/blob/master/available_images.md#large-model-inference-containers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a174b36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_uri = image_uris.retrieve(\n",
    "        framework=\"djl-deepspeed\",\n",
    "        region=sess.boto_session.region_name,\n",
    "        version=\"0.27.0\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11601839",
   "metadata": {},
   "source": [
    "### Upload artifact on S3 and create SageMaker model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38b1e5ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3 Code or Model tar ball uploaded to --- > s3://sagemaker-us-east-1-434444145045/large-model-lmi/code-qwen1.5-72B/mymodel.tar.gz\n"
     ]
    }
   ],
   "source": [
    "s3_code_prefix = \"large-model-lmi/code-qwen1.5-72B\"\n",
    "bucket = sess.default_bucket()  # bucket to house artifacts\n",
    "code_artifact = sess.upload_data(\"mymodel.tar.gz\", bucket, s3_code_prefix)\n",
    "print(f\"S3 Code or Model tar ball uploaded to --- > {code_artifact}\")\n",
    "\n",
    "model = Model(image_uri=image_uri, model_data=code_artifact, role=role)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004f39f6",
   "metadata": {},
   "source": [
    "### 4.2 Create SageMaker endpoint\n",
    "\n",
    "You need to specify the instance to use and endpoint names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e0e61cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------!"
     ]
    }
   ],
   "source": [
    "instance_type = \"ml.g5.12xlarge\"\n",
    "endpoint_name = sagemaker.utils.name_from_base(\"lmi-model-qwen1-5-72B\")\n",
    "\n",
    "model.deploy(initial_instance_count=1,\n",
    "             instance_type=instance_type,\n",
    "             endpoint_name=endpoint_name,\n",
    "             # container_startup_health_check_timeout=3600\n",
    "            )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e3421f4-12e5-4ec5-8b66-4ef1cc961c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lmi-model-qwen1-5-72B-2024-05-23-13-32-16-606\n"
     ]
    }
   ],
   "source": [
    "# endpoint_name = 'lmi-model-qwen1-5-72B-2024-05-23-09-10-23-101'\n",
    "print(endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a8df35b4-886d-441c-98b2-0a3f96e02b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# our requests and responses will be in json format so we specify the serializer and the deserializer\n",
    "predictor = sagemaker.Predictor(\n",
    "    endpoint_name=endpoint_name,\n",
    "    sagemaker_session=sess,\n",
    "    serializer=serializers.JSONSerializer(),\n",
    "    deserializer=sagemaker.deserializers.JSONDeserializer(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602f5040-ef47-48a5-89ee-24fb331450ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58db992c-1293-438d-a666-e0dbd8473a7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb63ee65",
   "metadata": {},
   "source": [
    "## Step 5: Test and benchmark the inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ee11ce2-c488-42c5-89eb-df453878c245",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.31.0)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.41.1-py3-none-any.whl.metadata (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.3)\n",
      "Collecting huggingface-hub<1.0,>=0.23.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.23.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers)\n",
      "  Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\n",
      "Downloading transformers-4.41.1-py3-none-any.whl (9.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m74.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.23.1-py3-none-any.whl (401 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.3/401.3 kB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m76.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: huggingface-hub, tokenizers, transformers\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface_hub 0.22.0\n",
      "    Uninstalling huggingface_hub-0.22.0:\n",
      "      Successfully uninstalled huggingface_hub-0.22.0\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.13.3\n",
      "    Uninstalling tokenizers-0.13.3:\n",
      "      Successfully uninstalled tokenizers-0.13.3\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.31.0\n",
      "    Uninstalling transformers-4.31.0:\n",
      "      Successfully uninstalled transformers-4.31.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "autogluon-multimodal 0.8.2 requires transformers[sentencepiece]<4.32.0,>=4.31.0, but you have transformers 4.41.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed huggingface-hub-0.23.1 tokenizers-0.19.1 transformers-4.41.1\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aaae61f7-b669-4a02-97a9-85085db6632c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "MODEL_DIR = \"Qwen/Qwen1.5-72B-Chat-AWQ\"\n",
    "# model = AutoModelForCausalLM.from_pretrained(MODEL_DIR, torch_dtype=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR, use_fast=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2bcef095",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'generated_text': '世界第二高峰是乔戈里峰，又称K2峰，海拔8,611米，位于巴基斯坦和中国交界的喀喇昆仑山脉。'}\n"
     ]
    }
   ],
   "source": [
    "prompt = \"世界上第二高峰是哪座？\"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "inputs = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")\n",
    "parameters = {\n",
    "        \"max_new_tokens\":1024, \n",
    "        \"do_sample\": True,\n",
    "        \"stop_token_ids\":[151645,151643],\n",
    "        \"repetition_penalty\": 1.05,\n",
    "        \"temperature\": 0.7,\n",
    "        \"top_p\": 0.8,\n",
    "        \"top_k\": 20\n",
    "    }\n",
    "response = predictor.predict(\n",
    "    {\"inputs\": inputs, \"parameters\": parameters}\n",
    ")\n",
    "# text = str(response, \"utf-8\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95732e49-db07-4de2-ae1d-8ed96e95f056",
   "metadata": {},
   "source": [
    "# Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "11c67435-fc81-42ae-85c5-608a9eb0e366",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "\n",
    "smr_client = boto3.client(\"sagemaker-runtime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2cae82c8-c390-4d70-ac18-f1d71c852727",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import json\n",
    "\n",
    "class TokenIterator:\n",
    "    def __init__(self, stream):\n",
    "        self.byte_iterator = iter(stream)\n",
    "        self.buffer = io.BytesIO()\n",
    "        self.read_pos = 0\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        while True:\n",
    "            self.buffer.seek(self.read_pos)\n",
    "            line = self.buffer.readline()\n",
    "            \n",
    "            # print(line)\n",
    "            if line and line[-1] == ord(\"\\n\"):\n",
    "                self.read_pos += len(line)\n",
    "                full_line = line[:-1].decode(\"utf-8\")\n",
    "                # print(full_line)\n",
    "                line_data = json.loads(full_line.lstrip(\"data:\").rstrip(\"/n\"))\n",
    "                return line_data[\"token\"].get(\"text\", \"\")\n",
    "            chunk = next(self.byte_iterator)\n",
    "            self.buffer.seek(0, io.SEEK_END)\n",
    "            self.buffer.write(chunk[\"PayloadPart\"][\"Bytes\"])\n",
    "        \n",
    "def get_realtime_response_stream(sagemaker_runtime, endpoint_name, payload):\n",
    "    response_stream = sagemaker_runtime.invoke_endpoint_with_response_stream(\n",
    "        EndpointName=endpoint_name,\n",
    "        Body=json.dumps(payload),\n",
    "        ContentType=\"application/json\",\n",
    "        CustomAttributes='accept_eula=false'\n",
    "    )\n",
    "    return response_stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c16918d8-35d9-4b56-ad50-73f7ab858a1e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "世界第二高峰是乔戈里峰，又称K2峰，海拔8,611米，位于巴基斯坦和中国交界的喀喇昆仑山脉。"
     ]
    }
   ],
   "source": [
    "prompt = \"世界上第二高峰是哪座？\"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "inputs = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")\n",
    "\n",
    "parameters = {\n",
    "        \"max_new_tokens\":1024, \n",
    "        \"do_sample\": True,\n",
    "        \"stop_token_ids\":[151645,151643],\n",
    "        \"repetition_penalty\": 1.05,\n",
    "        \"temperature\": 0.7,\n",
    "        \"top_p\": 0.8,\n",
    "        \"top_k\": 20,\n",
    "    }\n",
    "\n",
    "payload = {\n",
    "    \"inputs\":  inputs,\n",
    "    \"parameters\": parameters,\n",
    "    \"stream\": True ## <-- to have response stream.\n",
    "}\n",
    "response_stream = get_realtime_response_stream(smr_client, endpoint_name, payload)\n",
    "# print_response_stream(response_stream)\n",
    "for token in TokenIterator(response_stream[\"Body\"]):\n",
    "    # pass\n",
    "    print(token, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3479b15b-6b56-40d4-a0ed-15da2056a8b0",
   "metadata": {},
   "source": [
    "## Performance test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "795f1ff9-3c21-48a7-b63a-571eabbd4a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /opt/conda/lib/python3.10/site-packages (0.1.9)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.4.49)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (3.9.3)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.6.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.21 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.0.29)\n",
      "Requirement already satisfied: langchain-core<0.2,>=0.1.26 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.1.31)\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.10.14)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Requirement already satisfied: anyio<5,>=3 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.2,>=0.1.26->langchain) (3.7.1)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.2,>=0.1.26->langchain) (23.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.0->langchain) (3.9.15)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.26->langchain) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.26->langchain) (1.2.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c07e9e5d-e63b-4964-9603-e8f749da2de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b25bea7f-e16d-4a32-860f-b40e34534576",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \\\n",
    "\"\"\"你是一名小说家，热衷于创意写作和编写故事。 \n",
    "请帮我编写一个故事，对象是10-12岁的小学生\n",
    "故事背景：\n",
    "讲述一位名叫莉拉的年轻女子发现自己有控制天气的能力。她住在一个小镇上，每个人都互相认识。\n",
    "其他要求：\n",
    "-避免暴力，色情，粗俗的语言\n",
    "-长度要求不少于500字\n",
    "请开始：\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9627af8a-1106-42f9-9e83-4f57edd04edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def invoke_sagemaker(prompt):\n",
    "    messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    inputs = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    parameters = {\n",
    "            \"max_new_tokens\":100, \n",
    "            \"do_sample\": True,\n",
    "            \"stop_token_ids\":[151645,151643],\n",
    "            \"repetition_penalty\": 1.05,\n",
    "            \"temperature\": 0.7,\n",
    "            \"top_p\": 0.8,\n",
    "            \"top_k\": 250\n",
    "        }\n",
    "    response = predictor.predict(\n",
    "        {\"inputs\": inputs, \"parameters\": parameters}\n",
    "    )\n",
    "    print(response)\n",
    "    return response['generated_text']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6b9c2a59-2a8a-4e0a-ac8a-cbcb4c676846",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = RunnableLambda(invoke_sagemaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a3b2ca1a-8e1b-4646-b8a4-1b78ef93e051",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a920858f-12e4-48c6-b257-31cae0c03032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'generated_text': '在一个宁静的小镇上，住着一个活泼开朗的小女孩，名叫莉拉。莉拉是个十岁的小学生，她的眼睛像两颗闪烁的星星，总是充满了好奇和探索的光芒。这个小镇被绿色的田野和蔚蓝的天空环绕，生活平静而和谐。\\n\\n有一天，莉拉在放学回家的路上，突然天空乌云密布，电闪雷鸣。她看到一只小鸟在风雨中挣扎，试图找到避雨的地方。莉拉心中'}\n",
      "time cost:3.8615078926086426\n"
     ]
    }
   ],
   "source": [
    "time1 = time.time()\n",
    "await chain.abatch([text1]*1)\n",
    "print(f'time cost:{time.time()-time1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "49ba7d86-d2f3-4daa-b5f9-8645cc236e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'generated_text': '在一个宁静的小村庄里，住着一个活泼开朗的小女孩，名叫莉拉。莉拉有一头金色的卷发，眼睛像晴朗的天空一样湛蓝。她的笑容总是能照亮整个小镇，而她的秘密，就像天空中的云朵，神秘又迷人。\\n\\n有一天，莉拉在森林里玩耍，无意中发现了自己的特殊能力——她可以控制天气。当她心情愉快时，天空就会放晴，阳光洒满大地；当她感到伤心'}\n",
      "{'generated_text': '在阳光明媚的艾尔小镇上，住着一个活泼开朗的小女孩，名叫莉拉。莉拉是个普通的小学生，喜欢画画，热爱大自然，尤其是那些变幻莫测的云朵。然而，她的生活在一个普通的午后发生了改变。\\n\\n那天，莉拉在后院的苹果树下看书，突然一片乌云遮住了太阳，让她感到惊讶。她抬头看去，只见一朵巨大的乌云正快速向小镇飘来。她疑惑地伸出手'}\n",
      "{'generated_text': '在一个名叫晴空镇的小地方，住着一个活泼可爱的10岁女孩，名叫莉拉。莉拉拥有一头亮丽的金色卷发和一双闪烁着好奇光芒的湛蓝眼睛。这个小镇以其四季如春的气候闻名，人们总是笑容满面，和谐共处。\\n\\n一天，莉拉在森林里的秘密基地玩耍，突然天空乌云密布，电闪雷鸣。她惊讶地发现，只要她心里想着晴天，乌云'}\n",
      "{'generated_text': '在一个名叫晴空镇的小镇上，住着一个活泼可爱的小女孩，名叫莉拉。莉拉有着明亮的蓝眼睛和一头乱蓬蓬的金发，她的笑容总是像阳光一样温暖。这个小镇以四季如春的气候闻名，人们在这里过着宁静而和谐的生活。\\n\\n一天，莉拉在后院玩耍时，无意中发现了一个神奇的秘密。当她全心全意地想象着雨滴落在手中的情景，天空突然乌云'}\n",
      "{'generated_text': '故事标题：莉拉与天空的秘密\\n\\n在宁静的艾尔文小镇上，住着一个活泼可爱的小女孩，名叫莉拉。她有一头金色的卷发，眼睛像湖水一样湛蓝，总是闪烁着好奇的光芒。莉拉是个特别的孩子，她对天空有着异乎寻常的热爱，每天放学后，她都会坐在后院的大橡树下，仰望那片无尽的蓝色。\\n\\n有一天，当莉拉如常地'}\n",
      "time cost:6.017059326171875\n"
     ]
    }
   ],
   "source": [
    "time1 = time.time()\n",
    "await chain.abatch([text1]*5)\n",
    "print(f'time cost:{time.time()-time1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4880d79d-6ffd-4614-a28e-912a337c8512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.666666666666668"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100/6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cd9042",
   "metadata": {},
   "source": [
    "## Clean up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d674b41",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ClientError",
     "evalue": "An error occurred (ValidationException) when calling the DeleteEndpoint operation: Could not find endpoint \"lmi-model-qwen1-5-72B-2024-05-23-09-10-23-101\".",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdelete_endpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendpoint_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m sess\u001b[38;5;241m.\u001b[39mdelete_endpoint_config(endpoint_name)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# model.delete_model()\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/session.py:4636\u001b[0m, in \u001b[0;36mSession.delete_endpoint\u001b[0;34m(self, endpoint_name)\u001b[0m\n\u001b[1;32m   4630\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Delete an Amazon SageMaker ``Endpoint``.\u001b[39;00m\n\u001b[1;32m   4631\u001b[0m \n\u001b[1;32m   4632\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   4633\u001b[0m \u001b[38;5;124;03m    endpoint_name (str): Name of the Amazon SageMaker ``Endpoint`` to delete.\u001b[39;00m\n\u001b[1;32m   4634\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4635\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDeleting endpoint with name: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, endpoint_name)\n\u001b[0;32m-> 4636\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdelete_endpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mEndpointName\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/botocore/client.py:565\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    561\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    562\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_operation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() only accepts keyword arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    563\u001b[0m     )\n\u001b[1;32m    564\u001b[0m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[0;32m--> 565\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/botocore/client.py:1021\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m   1017\u001b[0m     error_code \u001b[38;5;241m=\u001b[39m error_info\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQueryErrorCode\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m error_info\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m   1018\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCode\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1019\u001b[0m     )\n\u001b[1;32m   1020\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mfrom_code(error_code)\n\u001b[0;32m-> 1021\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1023\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parsed_response\n",
      "\u001b[0;31mClientError\u001b[0m: An error occurred (ValidationException) when calling the DeleteEndpoint operation: Could not find endpoint \"lmi-model-qwen1-5-72B-2024-05-23-09-10-23-101\"."
     ]
    }
   ],
   "source": [
    "sess.delete_endpoint(endpoint_name)\n",
    "sess.delete_endpoint_config(endpoint_name)\n",
    "# model.delete_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781462bd-3971-491a-bfa6-c6e5c9539932",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
